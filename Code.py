# -*- coding: utf-8 -*-
"""SentiAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14tCqFHJTt5fMfd_95e7hMq-AyzFv4Ax1
"""

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

df = pd.read_csv('/content/train.csv',encoding='unicode_escape')[['text', 'sentiment']]

import os
import re
import math
import string
import codecs
import json
from itertools import product
from inspect import getsourcefile
from io import open

B_INCR = 0.3
B_DECR = -0.3

C_INCR = 0.75
N_SCALAR = -0.75

NEGATE = ["aint", "arent", "cannot", "cant", "couldnt", "darent", "didnt", "doesnt",
        "ain't", "aren't", "can't", "couldn't", "daren't", "didn't", "doesn't",
        "dont", "hadnt", "hasnt", "havent", "isnt", "mightnt", "mustnt", "neither",
        "don't", "hadn't", "hasn't", "haven't", "isn't", "mightn't", "mustn't",
        "neednt", "needn't", "never", "none", "nope", "nor", "not", "nothing", "nowhere",
        "oughtnt", "shant", "shouldnt", "uhuh", "wasnt", "werent",
        "oughtn't", "shan't", "shouldn't", "uh-uh", "wasn't", "weren't",
        "without", "wont", "wouldnt", "won't", "wouldn't", "rarely", "seldom", "despite"]

BOOSTER_DICT = {"absolutely": B_INCR, "amazingly": B_INCR, "awfully": B_INCR,
                "completely": B_INCR, "considerable": B_INCR, "considerably": B_INCR,
                "decidedly": B_INCR, "deeply": B_INCR, "effing": B_INCR, "enormous": B_INCR, "enormously": B_INCR,
                "entirely": B_INCR, "especially": B_INCR, "exceptional": B_INCR, "exceptionally": B_INCR,
                "extreme": B_INCR, "extremely": B_INCR,
                "fabulously": B_INCR, "flipping": B_INCR, "flippin": B_INCR, "frackin": B_INCR, "fracking": B_INCR,
                "fricking": B_INCR, "frickin": B_INCR, "frigging": B_INCR, "friggin": B_INCR, "fully": B_INCR,
                "fuckin": B_INCR, "fucking": B_INCR, "fuggin": B_INCR, "fugging": B_INCR,
                "greatly": B_INCR, "hella": B_INCR, "highly": B_INCR, "hugely": B_INCR,
                "incredible": B_INCR, "incredibly": B_INCR, "intensely": B_INCR,
                "major": B_INCR, "majorly": B_INCR, "more": B_INCR, "most": B_INCR, "particularly": B_INCR,
                "purely": B_INCR, "quite": B_INCR, "really": B_INCR, "remarkably": B_INCR,
                "so": B_INCR, "substantially": B_INCR,
                "thoroughly": B_INCR, "total": B_INCR, "totally": B_INCR, "tremendous": B_INCR, "tremendously": B_INCR,
                "uber": B_INCR, "unbelievably": B_INCR, "unusually": B_INCR, "utter": B_INCR, "utterly": B_INCR,
                "very": B_INCR,
                "almost": B_DECR, "barely": B_DECR, "hardly": B_DECR, "just enough": B_DECR,
                "kind of": B_DECR, "kinda": B_DECR, "kindof": B_DECR, "kind-of": B_DECR,
                "less": B_DECR, "little": B_DECR, "marginal": B_DECR, "marginally": B_DECR,
                "occasional": B_DECR, "occasionally": B_DECR, "partly": B_DECR,
                "scarce": B_DECR, "scarcely": B_DECR, "slight": B_DECR, "slightly": B_DECR, "somewhat": B_DECR,
                "sort of": B_DECR, "sorta": B_DECR, "sortof": B_DECR, "sort-of": B_DECR}

def negated(input_words):
    input_words = [word.lower() for word in input_words.split()]
    for word in NEGATE:
        if word in input_words:
            return True
    return False

negated("This product shouldn't be bought")

negated("This product is good")

def normalise(score, alpha=15):
    norm_score = score/math.sqrt((score*score) + alpha)
    if norm_score <= -.25:
        return "negative"
    if norm_score >= 0.25:
        return "positive"
    return "neutral"

normalise(4)

normalise(-4)

normalise(.01)

def allcaps(words):
    allcap_words = 0
    for word in words:
        if word.isupper():
            allcap_words += 1
    if 0 < allcap_words < len(words):
        return True
    return False

def strip_punc(word):
    stripped = word.strip(string.punctuation)
    if len(stripped) <= 2:
        return word
    return stripped

def parse_emoji(text,emojis):
    text_only = ""
    prev_space = True
    for character in text:
        if character in emojis:
            meaning = emojis[character]
            if not prev_space:
                text_only += ' '
            text_only += meaning
        else:
            text_only += character
            prev_space = character == ' '
    return text_only.strip()

class SentiText(object):
    def __init__(self, text):
        self.text = text
        wes = text.split()
        self.words_emoti = list(map(strip_punc,wes))
        self.is_all_cap = allcaps(self.words_emoti)

obj = SentiText("  My name is prashant.  :)")

obj.words_emoti

obj.is_all_cap

def load_emojis():
    emojis = {}
    with codecs.open('/content/emoji_utf8.txt', encoding='utf-8') as f:
        emoji = f.read()
        for line in emoji.split('\n'):
            if not line:
                continue
            emoji, meaning = line.strip().split('\t')[0:2]
            emojis[emoji] = meaning
    return emojis

def load_lexicon():
    lexicon = {}
    with codecs.open('/content/emoji.txt', encoding='utf-8') as f:
        lexicon_read = f.read()
        for line in lexicon_read.rstrip('\n').split('\n'):
            if not line:
                continue
            word, score = line.strip().split('\t')[0:2]
            lexicon[word] = float(score)
    return lexicon

class SentimentAnalysis:
    def __init__(self):
        self.lexicon = load_lexicon()
        self.emojis = load_emojis()

    def analyse_sentiment(self, text):

        text = parse_emoji(text, self.emojis)

        senti = SentiText(text)

        sentiments = []

        for i, item in enumerate(senti.words_emoti):
            sentiment = 0
            if item.lower() in BOOSTER_DICT:
                sentiments.append(sentiment)
                continue

            if item.lower() in self.lexicon:
                sentiment = self.lexicon[item.lower()]

                if i > 0 and senti.words_emoti[i - 1].lower() in NEGATE:
                    sentiment *= -1
            if item.isupper() and senti.is_all_cap:
              if sentiment > 0:
                sentiment += C_INCR
              else:
                sentiment -= C_INCR

            sentiments.append(sentiment)

        compound = sum(sentiments)


        return normalise(compound)

obj = SentimentAnalysis()

obj.analyse_sentiment("I am not happy with a product!!!")

obj = SentimentAnalysis()

# Test sentences
test_sentences = [
    "I love this! üòä",
    "This is terrible! üò¢",
    "Wow, what a great day!!! üòç",
    "I am not happy with this service. üò°",
]

for sentence in test_sentences:
    result = obj.analyse_sentiment(sentence)
    print(f"Sentence: {sentence}")
    print(f"Result: {result}")
    print("-" * 30)

df.sample(5)

df.isna().sum()

df.dropna(inplace=True)

df.isna().sum()

def analyse(text):
    if isinstance(text, float) == True:
        return "Float"
    obj = SentimentAnalysis()
    return obj.analyse_sentiment(text)

y_pred = df['text'].apply(analyse)

y_pred

y_test = df['sentiment']

accuracy_score(y_test, y_pred)

